# Local Data Platform (LDP) Environment Configuration
# Copy this file to .env and customize as needed
# cp config/env/.env.example .env

# =============================================================================
# MINIKUBE CONFIGURATION
# =============================================================================
MINIKUBE_CPUS=4
MINIKUBE_MEMORY=8192
MINIKUBE_DISK_SIZE=50g
KUBERNETES_VERSION=v1.34.0

# =============================================================================
# KUBERNETES NAMESPACE
# =============================================================================
LDP_NAMESPACE=ldp

# =============================================================================
# AIRFLOW CONFIGURATION
# =============================================================================
AIRFLOW_ADMIN_USER=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_ADMIN_EMAIL=admin@example.com
AIRFLOW_WEBSERVER_PORT=30080
AIRFLOW_EXECUTOR=LocalExecutor

# Airflow connections (for DAGs)
AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
AIRFLOW__CORE__LOAD_EXAMPLES=false

# =============================================================================
# SPARK CONFIGURATION
# =============================================================================
SPARK_MASTER_URL=spark://spark-master:7077
SPARK_MASTER_WEB_PORT=30707
SPARK_WORKER_CORES=2
SPARK_WORKER_MEMORY=2g
SPARK_WORKER_INSTANCES=2

# Spark defaults
SPARK_DRIVER_MEMORY=1g
SPARK_EXECUTOR_MEMORY=1g

# =============================================================================
# MINIO (S3-COMPATIBLE STORAGE) CONFIGURATION
# =============================================================================
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=minioadmin
MINIO_API_PORT=30900
MINIO_CONSOLE_PORT=30901
MINIO_REGION=us-east-1

# MinIO buckets (created by init-minio script)
MINIO_BUCKET_DATALAKE=datalake
MINIO_BUCKET_WAREHOUSE=warehouse
MINIO_BUCKET_STAGING=staging

# S3 endpoint for applications
S3_ENDPOINT=http://minio:9000
S3_ACCESS_KEY=${MINIO_ROOT_USER}
S3_SECRET_KEY=${MINIO_ROOT_PASSWORD}

# =============================================================================
# POSTGRESQL CONFIGURATION
# =============================================================================
POSTGRES_HOST=postgresql
POSTGRES_PORT=5432
POSTGRES_DB=metastore
POSTGRES_USER=ldp
POSTGRES_PASSWORD=ldppassword

# External port for local access
POSTGRES_EXTERNAL_PORT=30432

# =============================================================================
# JUPYTER CONFIGURATION
# =============================================================================
JUPYTER_PORT=30888
JUPYTER_TOKEN=
# Leave JUPYTER_TOKEN empty for token-based auth (check logs for token)
# Or set a password: JUPYTER_TOKEN=your-secure-password

# =============================================================================
# ICEBERG CONFIGURATION
# =============================================================================
ICEBERG_CATALOG_TYPE=hadoop
ICEBERG_WAREHOUSE_PATH=s3a://warehouse/
ICEBERG_SPARK_RUNTIME=org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.10.0

# =============================================================================
# TERRAFORM CONFIGURATION
# =============================================================================
TF_VAR_environment=dev
TF_VAR_namespace=${LDP_NAMESPACE}

# =============================================================================
# LOGGING AND MONITORING
# =============================================================================
LOG_LEVEL=INFO

# Prometheus (optional)
PROMETHEUS_ENABLED=false
PROMETHEUS_PORT=30090

# Grafana (optional)
GRAFANA_ENABLED=false
GRAFANA_PORT=30030
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# Enable debug mode for development
DEBUG_MODE=false

# Hot reload for DAGs
AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=30

# Python path for development
PYTHONPATH=/opt/airflow/dags:/opt/airflow/plugins

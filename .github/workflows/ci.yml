---
name: CI Testing

'on':
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  terraform-validate:
    name: Terraform Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.14.3

      - name: Terraform Format Check
        run: |
          cd terraform
          terraform fmt -check -recursive

      - name: Terraform Init
        run: |
          cd terraform
          terraform init -backend=false

      - name: Terraform Validate
        run: |
          cd terraform
          terraform validate

      - name: Terraform Plan (Local)
        run: |
          cd terraform
          terraform plan -var-file=environments/local.tfvars -out=tfplan
        continue-on-error: true

  python-lint-and-test:
    name: Python Linting and Testing
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.14']
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pylint flake8 black
          pip install -r docker/airflow/requirements.txt
          pip install -r docker/spark/requirements.txt

      - name: Load example code and tests
        run: |
          make load-examples

      - name: Lint with flake8
        run: |
          # Stop the build if there are Python syntax errors or undefined names
          flake8 airflow/ spark/ tests/ examples/ --count --select=E9,F63,F7,F82 --show-source --statistics
          # Exit-zero treats all errors as warnings
          flake8 airflow/ spark/ tests/ examples/ --count --exit-zero \
            --max-complexity=10 --max-line-length=127 --statistics
        continue-on-error: true

      - name: Check code formatting with black
        run: |
          black --check airflow/ spark/ tests/ examples/
        continue-on-error: true

      - name: Lint with pylint
        run: |
          pylint airflow/ spark/ tests/ examples/ --exit-zero
        continue-on-error: true

      - name: Test Airflow DAGs
        run: |
          export PYTHONPATH="${PYTHONPATH}:${PWD}/airflow"
          pytest airflow/tests/ -v --tb=short

      - name: Test Spark transformations
        run: |
          export PYTHONPATH="${PYTHONPATH}:${PWD}/spark"
          pytest spark/tests/ -v --tb=short

      - name: Run integration tests
        run: |
          pytest tests/ -v --tb=short -m "not e2e"

  shellcheck:
    name: Shell Script Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run ShellCheck
        uses: ludeeus/action-shellcheck@master
        with:
          scandir: './scripts'
          severity: warning

  yaml-lint:
    name: YAML Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install yamllint
        run: pip install yamllint

      - name: Lint Kubernetes manifests
        run: |
          yamllint kubernetes/ -d '{extends: default, rules: {line-length: {max: 120}}}'
        continue-on-error: true

      - name: Lint GitHub workflows
        run: |
          yamllint .github/workflows/ -d '{extends: default, rules: {line-length: {max: 120}}}'
        continue-on-error: true

  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [airflow, spark, jupyter]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build ${{ matrix.service }} Docker image
        run: |
          if [ "${{ matrix.service }}" = "airflow" ]; then
            docker build -f docker/airflow/Dockerfile -t ldp-airflow:test .
          elif [ "${{ matrix.service }}" = "spark" ]; then
            docker build -f docker/spark/Dockerfile -t ldp-spark:test .
          elif [ "${{ matrix.service }}" = "jupyter" ]; then
            docker build -f docker/jupyter/Dockerfile -t ldp-jupyter:test .
          fi

  documentation:
    name: Documentation Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check README
        run: |
          if [ ! -f README.md ]; then
            echo "README.md not found"
            exit 1
          fi
          echo "README.md exists and is valid"

      - name: Check documentation files
        run: |
          required_docs=("docs/project-structure.md" "docs/setup-guide.md")
          for doc in "${required_docs[@]}"; do
            if [ ! -f "$doc" ]; then
              echo "Missing required documentation: $doc"
              exit 1
            fi
          done
          echo "All required documentation files exist"

      - name: Validate Markdown links
        uses: gaurav-nelson/github-action-markdown-link-check@v1
        with:
          use-quiet-mode: 'yes'
          config-file: '.github/markdown-link-check-config.json'
        continue-on-error: true

  makefile-test:
    name: Makefile Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check Makefile exists
        run: |
          if [ ! -f Makefile ]; then
            echo "Makefile not found"
            exit 1
          fi

      - name: Validate Makefile syntax
        run: |
          make -n help

      - name: List available targets
        run: |
          echo "Available Makefile targets:"
          make help

  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'table'
          exit-code: '0'
          severity: 'CRITICAL,HIGH'

      - name: Check for secrets in code
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: ""
          head: ""
        continue-on-error: true

  project-structure:
    name: Project Structure Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate project structure
        run: |
          required_dirs=(
            "terraform"
            "kubernetes"
            "airflow/dags"
            "airflow/plugins"
            "spark/jobs"
            "spark/lib"
            "docker"
            "scripts"
            "config"
            "tests"
            "examples"
          )

          missing_dirs=()
          for dir in "${required_dirs[@]}"; do
            if [ ! -d "$dir" ]; then
              missing_dirs+=("$dir")
            fi
          done

          if [ ${#missing_dirs[@]} -ne 0 ]; then
            echo "Missing required directories:"
            printf '%s\n' "${missing_dirs[@]}"
            exit 1
          fi

          echo "All required directories exist"

      - name: Check for required files
        run: |
          required_files=(
            "README.md"
            "Makefile"
            ".gitignore"
            "terraform/main.tf"
            "terraform/variables.tf"
            "terraform/outputs.tf"
          )

          missing_files=()
          for file in "${required_files[@]}"; do
            if [ ! -f "$file" ]; then
              missing_files+=("$file")
            fi
          done

          if [ ${#missing_files[@]} -ne 0 ]; then
            echo "Missing required files:"
            printf '%s\n' "${missing_files[@]}"
            exit 1
          fi

          echo "All required files exist"

  cluster-integration-test:
    name: Cluster Integration Test
    runs-on: ubuntu-latest
    needs: [terraform-validate, docker-build]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.14.3

      - name: Start Minikube
        uses: medyagh/setup-minikube@latest
        with:
          cpus: 2
          memory: 4096
          kubernetes-version: 1.34.0

      - name: Verify Minikube is running
        run: |
          kubectl cluster-info
          kubectl get nodes

      - name: Deploy infrastructure with Terraform
        run: |
          cd terraform
          terraform init -backend=false
          terraform apply -var-file=environments/local.tfvars -auto-approve
        timeout-minutes: 20

      - name: Wait for Airflow database migrations
        run: |
          echo "Waiting for Helm-managed database migrations to complete..."
          # Wait for the migration job created by the Helm chart
          timeout 180 bash -c 'until kubectl get job -n ldp \
            -l app.kubernetes.io/component=run-airflow-migrations 2>/dev/null | grep -q "1/1"; do \
            echo "Waiting for migration job..."; sleep 5; done' || true

          # If migration job exists, wait for it to complete
          if kubectl get job -n ldp -l app.kubernetes.io/component=run-airflow-migrations &>/dev/null; then
            kubectl wait --for=condition=complete job -n ldp \
              -l app.kubernetes.io/component=run-airflow-migrations --timeout=120s || true
          fi

          echo "Migration check complete"

      - name: Wait for pods to be ready
        run: |
          echo "Waiting for all pods to be ready..."
          kubectl wait --for=condition=ready pod --all -n ldp --timeout=300s || true

      - name: Check all pods status
        run: |
          echo "Checking pod status in ldp namespace:"
          kubectl get pods -n ldp -o wide

          # Check if all pods are running
          NOT_RUNNING=$(kubectl get pods -n ldp \
            --field-selector=status.phase!=Running --no-headers 2>/dev/null | wc -l)
          if [ "$NOT_RUNNING" -gt 0 ]; then
            echo "Warning: $NOT_RUNNING pod(s) are not in Running state"
            kubectl get pods -n ldp --field-selector=status.phase!=Running
          fi

      - name: Check deployments
        run: |
          echo "Checking deployments:"
          kubectl get deployments -n ldp

      - name: Check services
        run: |
          echo "Checking services:"
          kubectl get services -n ldp

      - name: Wait for MinIO to be ready
        run: |
          echo "Waiting for MinIO service to be ready..."
          kubectl wait --for=condition=ready pod -n ldp -l app=minio --timeout=120s || true
          echo "MinIO pod status:"
          kubectl get pods -n ldp -l app=minio

      - name: Initialize MinIO buckets
        run: |
          echo "Creating MinIO buckets..."
          kubectl apply -f kubernetes/jobs/init-minio-buckets.yaml
          kubectl wait --for=condition=complete job/init-minio-buckets -n ldp --timeout=180s || true

          echo "Job status:"
          kubectl get job init-minio-buckets -n ldp

          if kubectl get job init-minio-buckets -n ldp -o jsonpath='{.status.succeeded}' | grep -q 1; then
            echo "MinIO buckets initialized successfully"
          else
            echo "Warning: MinIO bucket initialization may have failed, checking logs..."
            POD=$(kubectl get pods -n ldp -l job-name=init-minio-buckets \
              -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$POD" ]; then
              kubectl logs -n ldp $POD --tail=50 || true
            fi
          fi

      - name: Upload test data to MinIO
        run: |
          echo "Creating sample test data..."
          cat > /tmp/upload_script.sh <<'SCRIPT'
          #!/bin/sh
          mc alias set ldp http://minio:9000 admin minioadmin
          mc mb --ignore-existing ldp/datalake/raw/test
          cat <<'DATA' | mc pipe ldp/datalake/raw/test/sample_data.csv
          id,name,value,date
          1,product_a,100,2024-01-01
          2,product_b,200,2024-01-02
          3,product_c,300,2024-01-03
          4,product_d,400,2024-01-04
          5,product_e,500,2024-01-05
          DATA
          echo "Test data uploaded successfully"
          mc ls ldp/datalake/raw/test/
          SCRIPT

          echo "Uploading test data to MinIO using mc client..."
          kubectl run minio-upload --rm -i --restart=Never \
            --image=minio/mc:latest -n ldp \
            --command -- /bin/sh -s < /tmp/upload_script.sh

      - name: Test complete data pipeline
        run: |
          echo "Testing end-to-end data pipeline..."

          # Wait for Airflow webserver to be ready
          echo "Waiting for Airflow to be ready..."
          kubectl wait --for=condition=ready pod -n ldp -l component=webserver --timeout=120s || true

          # Port forward Airflow (in background)
          kubectl port-forward -n ldp svc/airflow-webserver 8080:8080 &
          sleep 10

          # Trigger the example DAG via REST API
          echo "Triggering example_spark_job DAG..."
          curl -X POST "http://localhost:8080/api/v1/dags/example_spark_job/dagRuns" \
            -H "Content-Type: application/json" \
            -u "admin:admin" \
            -d '{"conf":{}}' || echo "DAG trigger failed (DAG may not be loaded yet)"

          # Check DAG status
          echo "Checking available DAGs..."
          curl -s "http://localhost:8080/api/v1/dags" \
            -u "admin:admin" | head -20 || echo "Could not fetch DAGs"

          echo "Pipeline test initiated"

      - name: Describe failed pods (if any)
        if: failure()
        run: |
          echo "Describing pods that are not ready:"
          kubectl get pods -n ldp --field-selector=status.phase!=Running \
            --no-headers | awk '{print $1}' | while read pod; do
            echo "=== Describing pod: $pod ==="
            kubectl describe pod $pod -n ldp
            echo "=== Logs for pod: $pod ==="
            kubectl logs $pod -n ldp --tail=50 || true
          done

      - name: Get all resources in namespace
        if: always()
        run: |
          echo "All resources in ldp namespace:"
          kubectl get all -n ldp

  summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs:
      - terraform-validate
      - python-lint-and-test
      - shellcheck
      - yaml-lint
      - docker-build
      - documentation
      - makefile-test
      - security-scan
      - project-structure
      - cluster-integration-test
    if: always()
    steps:
      - name: Check CI Results
        run: |
          echo "CI Pipeline Summary:"
          echo "===================="
          echo "Terraform Validation: ${{ needs.terraform-validate.result }}"
          echo "Python Lint & Test: ${{ needs.python-lint-and-test.result }}"
          echo "ShellCheck: ${{ needs.shellcheck.result }}"
          echo "YAML Lint: ${{ needs.yaml-lint.result }}"
          echo "Docker Build: ${{ needs.docker-build.result }}"
          echo "Documentation: ${{ needs.documentation.result }}"
          echo "Makefile Test: ${{ needs.makefile-test.result }}"
          echo "Security Scan: ${{ needs.security-scan.result }}"
          echo "Project Structure: ${{ needs.project-structure.result }}"
          echo "Cluster Integration Test: ${{ needs.cluster-integration-test.result }}"
